{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMujg91fU/taS4upDG4/hUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mashrur-rahman-fahim/Machine_learning_projects/blob/main/00_pytorch_fundamentals_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create a random tensor with shape (7, 7)."
      ],
      "metadata": {
        "id": "pjKmdx9gI0Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "rand_tensor=torch.rand(7,7)\n",
        "rand_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKCPUoUIppO",
        "outputId": "30af1664-20cb-49d5-d74b-a99d9ffaae7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5153, 0.3227, 0.1825, 0.2982, 0.2684, 0.8212, 0.6890],\n",
              "        [0.6962, 0.7199, 0.1393, 0.1114, 0.7791, 0.0179, 0.7062],\n",
              "        [0.3587, 0.7271, 0.6907, 0.8979, 0.7952, 0.6222, 0.8494],\n",
              "        [0.8605, 0.0149, 0.7345, 0.1251, 0.0534, 0.4844, 0.1153],\n",
              "        [0.5597, 0.2895, 0.4170, 0.9894, 0.1936, 0.6065, 0.9296],\n",
              "        [0.2448, 0.8305, 0.2518, 0.5508, 0.4183, 0.7857, 0.1152],\n",
              "        [0.3558, 0.7354, 0.4552, 0.2866, 0.7170, 0.3467, 0.4497]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor)."
      ],
      "metadata": {
        "id": "mEzHCszwJcvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdmE6Ol8IZM_",
        "outputId": "122b6003-f70c-4a5c-feed-44670ff4e1b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2838],\n",
              "        [0.6454],\n",
              "        [1.8734],\n",
              "        [0.7676],\n",
              "        [1.6895],\n",
              "        [1.4852],\n",
              "        [1.0361]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import torch\n",
        "rand_tensor1=torch.rand(1,7)\n",
        "reshape_tensor1=torch.reshape(rand_tensor1,(7,1))\n",
        "torch.matmul(rand_tensor,reshape_tensor1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "rand_tensor1=torch.rand(1,7)\n",
        "torch.matmul(rand_tensor,rand_tensor1.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuF8f9nTJjom",
        "outputId": "776addd9-6578-4051-8ec7-51193665c518"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3982],\n",
              "        [1.4957],\n",
              "        [2.4668],\n",
              "        [0.9379],\n",
              "        [1.9409],\n",
              "        [1.3697],\n",
              "        [1.6070]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set the random seed to 0 and do exercises 2 & 3 over again.\n"
      ],
      "metadata": {
        "id": "KW4FmfF6LnM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "RANDOM_SEED=0\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "rand_tensor=torch.rand(7,7)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "rand_tensor1=torch.rand(1,7)\n",
        "torch.matmul(rand_tensor,rand_tensor1.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg0TCaJSLs91",
        "outputId": "5ac903c5-6c64-4df5-9a98-99fcf642c160"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5985],\n",
              "        [1.1173],\n",
              "        [1.2741],\n",
              "        [1.6838],\n",
              "        [0.8279],\n",
              "        [1.0347],\n",
              "        [1.2498]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
      ],
      "metadata": {
        "id": "bFsO0lP-PpEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.manual_seed(1234)\n"
      ],
      "metadata": {
        "id": "q_0OihE_Mwtt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n"
      ],
      "metadata": {
        "id": "wqaZlyU1QhBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(1234)\n",
        "rand_1=torch.rand(2,3)\n",
        "torch.manual_seed(1234)\n",
        "rand_2=torch.rand(2,3)\n",
        "if torch.cuda.is_available():\n",
        "  rand_1=rand_1.to(\"cuda\")\n",
        "  rand_2=rand_2.to(\"cuda\")\n",
        "\n",
        "print(rand_1)\n",
        "print(rand_2)\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js8ZpBOAQa3l",
        "outputId": "9c516ac4-5363-486f-f8a9-84bf11c0ef69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0290, 0.4019, 0.2598],\n",
            "        [0.3666, 0.0583, 0.7006]], device='cuda:0')\n",
            "tensor([[0.0290, 0.4019, 0.2598],\n",
            "        [0.3666, 0.0583, 0.7006]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)"
      ],
      "metadata": {
        "id": "1QQYRPkAUUNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_mul=torch.matmul(rand_1,rand_2.T)\n",
        "matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0uOs3qbQfSV",
        "outputId": "7d3abab2-fc6c-4680-be27-923cfa111995"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2299, 0.2161],\n",
              "        [0.2161, 0.6287]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Find the maximum and minimum values of the output of 7."
      ],
      "metadata": {
        "id": "CfRInJLfVz8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_mul.max(),matrix_mul.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBxLlJaxVzZ9",
        "outputId": "93a187c2-be9b-4284-d5ea-f7791f3359a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6287, device='cuda:0'), tensor(0.2161, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Find the maximum and minimum index values of the output of 7."
      ],
      "metadata": {
        "id": "_Ot99eAEWWb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(matrix_mul),torch.argmin(matrix_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsoxKrdNWS41",
        "outputId": "3e3ad1bf-a8b9-433a-b3b0-52e6ab488fd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3, device='cuda:0'), tensor(1, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n"
      ],
      "metadata": {
        "id": "i_lWkarVXWsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "rand_tensor=torch.rand(1,1,1,10)\n",
        "one_dim=torch.squeeze(rand_tensor)\n",
        "print(f\"first_tensor:{rand_tensor}\")\n",
        "print(f\"first_tensor_shape:{rand_tensor.shape}\")\n",
        "print(f\"second_tensor:{one_dim}\")\n",
        "print(f\"second_tensor_shape:{one_dim.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEjeDdgIXuss",
        "outputId": "6c8e799f-5c30-4562-acc6-b468110e25c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first_tensor:tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]])\n",
            "first_tensor_shape:torch.Size([1, 1, 1, 10])\n",
            "second_tensor:tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513])\n",
            "second_tensor_shape:torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2w-zuraYIOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}